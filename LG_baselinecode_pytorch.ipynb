{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lg basecode pytorch.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2uHh7CCsw0Y"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import urllib\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOSMayaMuNzb"
      },
      "source": [
        "os.chdir('C:/Users/user/Desktop/LG comp/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVIU8gqKffHg"
      },
      "source": [
        "데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4HY6UCItpg0"
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    \n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgkljaCUu18W"
      },
      "source": [
        "train_csv = pd.read_csv('./data/train.csv')\n",
        "test_csv = pd.read_csv('./data/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSlVboxyu149"
      },
      "source": [
        "train_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvUZh_tqu115"
      },
      "source": [
        "test_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQwh265Rp6h7"
      },
      "source": [
        "img_size= 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS--bZPup6h8"
      },
      "source": [
        "train_input_files =  glob(f'./data/train_input_img_{img_size}/*.npy')\n",
        "train_label_files = glob(f'./data/train_label_img_{img_size}/*.npy')\n",
        "\n",
        "val_input_files = glob(f'./data/val_input_img_{img_size}/*.npy')\n",
        "val_label_files = glob(f'./data/val_label_img_{img_size}/*.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TieLvZ0u1tB"
      },
      "source": [
        "len(train_input_files), len(train_label_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVarvzik954O"
      },
      "source": [
        "#참조\n",
        "https://blog.promedius.ai/pytorch_dataloader_1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKgRYv_3i5OM"
      },
      "source": [
        "AlbumentationsDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7L90bGojVLm"
      },
      "source": [
        "import albumentations\n",
        "import torch\n",
        "import albumentations.pytorch\n",
        "import torchvision\n",
        "\n",
        "# from albumentations.torch import ToTensor \n",
        "print(albumentations.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ppdES_gzqx"
      },
      "source": [
        "#원본 이미지로 불러올때 사용\n",
        "class AlbumentationsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir, y_dir,transform=None):\n",
        "        super().__init__()\n",
        "        self.transforms = transform\n",
        "        self.x_img = x_dir\n",
        "        self.y_img = y_dir   \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "        y_img = self.y_img[idx]\n",
        "        # Read an image with OpenCV\n",
        "        x_img = cv2.imread(x_img)\n",
        "        y_img =cv2.imread(y_img)\n",
        "        x_img= cv2.cvtColor(x_img, cv2.COLOR_BGR2RGB)\n",
        "        y_img= cv2.cvtColor(y_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=x_img,target_image=y_img)\n",
        "            image = augmented['image']\n",
        "            labeled = augmented['target_image']\n",
        "\n",
        "        return image, labeled "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUQfxxTLp6iB"
      },
      "source": [
        "#Crop 이미지로 불러올때 사용(baseline은 이미지를 크롭해서 npy format으로 저장해 불러옴)\n",
        "class AlbumentationsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir, y_dir,transform=None):\n",
        "        super().__init__()\n",
        "        self.transforms = transform\n",
        "        self.x_img = x_dir\n",
        "        self.y_img = y_dir  \n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "        x_img = np.load(x_img)\n",
        "        x_img = x_img.astype(np.float32)\n",
        "        \n",
        "        y_img = self.y_img[idx]\n",
        "        y_img = np.load(y_img)\n",
        "        y_img = y_img.astype(np.float32)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=x_img,target_image=y_img)\n",
        "            image = augmented['image']\n",
        "            labeled = augmented['target_image']\n",
        "\n",
        "        return image, labeled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo2zzY_Gp6iC"
      },
      "source": [
        "aug = albumentations.Compose([\n",
        "      albumentations.Resize(256, 256),\n",
        "      albumentations.HorizontalFlip(),\n",
        "      albumentations.RandomRotate90(),\n",
        "      albumentations.VerticalFlip(),\n",
        "      albumentations.MedianBlur(blur_limit=5),\n",
        "      albumentations.MotionBlur(),\n",
        "      albumentations.pytorch.transforms.ToTensorV2()\n",
        "      ],additional_targets={'target_image':'image'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxTvBIGiTWW"
      },
      "source": [
        "train_dataset = AlbumentationsDataset(train_input_files,train_label_files,transform=aug)\n",
        "vali_dataset = AlbumentationsDataset(val_input_files,val_label_files,transform=aug2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sliHE5ZMBPUn"
      },
      "source": [
        "train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=6,shuffle=False)\n",
        "vali_dataloader=torch.utils.data.DataLoader(vali_dataset,batch_size=6,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4t0Mn_wXp6iG"
      },
      "source": [
        "images,labels = next(iter(train_dataloader))\n",
        "\n",
        "print(images[0].shape)\n",
        "\n",
        "x=images[2].numpy()\n",
        "xx=np.transpose(x,(1,2,0)) #트렌스포즈 해주는 이유는 impose는 채널이 맨 뒤로감\n",
        "y=labels[2].numpy()\n",
        "yy=np.transpose(y,(1,2,0))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(xx)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(yy)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델은 오픈소스를 사용했으나 출처를 못 찾겠어서 생략합니다"
      ],
      "metadata": {
        "id": "RIjQ_wI9mrbt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9tyzAmRp6iM"
      },
      "source": [
        "sum([param.nelement() for param in model.parameters()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNcTy-lB_kEN"
      },
      "source": [
        "criterion = nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHlQBiVTb76k"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "kf = KFold(n_splits=5, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Thn2IjXkp6iP"
      },
      "source": [
        "import torch.cuda.amp as amp\n",
        "n_epochs=5\n",
        "batch_size=8\n",
        "\n",
        "scaler = amp.GradScaler()\n",
        "valid_loss_min = np.Inf\n",
        "train_loss = torch.zeros(n_epochs)\n",
        "valid_loss = torch.zeros(n_epochs)\n",
        "\n",
        "for fold,( train_ind, valid_ind) in enumerate(kf.split(train_dataset)):\n",
        "    \n",
        "    print('Starting fold = ', fold)\n",
        "\n",
        "    train_sampler_kfold = SubsetRandomSampler(train_ind)\n",
        "    valid_sampler_kfold = SubsetRandomSampler(valid_ind)\n",
        "    \n",
        "    train_loader_kfold = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler_kfold)\n",
        "    valid_loader_kfold = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler_kfold)\n",
        "\n",
        "    model = ResUnet(3).cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "    for e in np.arange(n_epochs): \n",
        "        print('Starting epoch = ', e)\n",
        "        \n",
        "        # Training\n",
        "        model.train()\n",
        "        for data,labels in tqdm(train_loader_kfold):\n",
        "            data = data.to(device=device, dtype=torch.float)\n",
        "            labels = labels.to(device=device, dtype=torch.float)\n",
        "            optimizer.zero_grad()\n",
        "            with amp.autocast():\n",
        "                output = model(data)\n",
        "                loss = criterion(output, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.update()\n",
        "            train_loss[e] += loss.item()\n",
        "            \n",
        "        train_loss[e] /= len(train_loader_kfold)\n",
        "\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, labels in tqdm(valid_loader_kfold):\n",
        "                data = data.to(device=device, dtype=torch.float)\n",
        "                labels = labels.to(device=device, dtype=torch.float)\n",
        "                \n",
        "                with amp.autocast():\n",
        "                    output = model(data)\n",
        "                    loss = criterion(output, labels)\n",
        "                    \n",
        "                valid_loss[e] += loss.item()\n",
        "            valid_loss[e] /= len(valid_loader_kfold)\n",
        "    \n",
        "    # print training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(e, train_loss[e], valid_loss[e]))\n",
        "\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "        if valid_loss[e] <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss[e]))\n",
        "            torch.save(model.state_dict(), 'model_'+str(fold)+'.pt')\n",
        "            valid_loss_min = valid_loss[e]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGlRjeorbiP0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss)\n",
        "plt.plot(valid_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT5SXo_Desoq"
      },
      "source": [
        "model.load_state_dict(torch.load('../model_1.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w67smvvjfmu"
      },
      "source": [
        "test_input_files = '../test_input_img/'+test_csv['input_img']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCvnqAnip6iR"
      },
      "source": [
        "images,labels = next(iter(test_dataloader))\n",
        "print(images.shape)\n",
        "\n",
        "x=images[0].numpy()\n",
        "xx=np.transpose(x,(1,2,0))\n",
        "y=labels[0].numpy()\n",
        "yy=np.transpose(y,(1,2,0))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(xx)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(yy)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 부분부터 baseline code와 동일"
      ],
      "metadata": {
        "id": "H74m7tAxouG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(img_paths, stride=32, batch_size=128):\n",
        "    results = []\n",
        "    for img_path in img_paths:\n",
        "        img = cv2.imread(img_path)\n",
        "        img = img.astype(np.float32)/255\n",
        "        crop = []\n",
        "        position = []\n",
        "        batch_count = 0\n",
        "\n",
        "        result_img = np.zeros_like(img)\n",
        "        voting_mask = np.zeros_like(img)\n",
        "\n",
        "        for top in tqdm(range(0, img.shape[0], stride)):\n",
        "            for left in range(0, img.shape[1], stride):\n",
        "                piece = np.zeros([img_size, img_size, 3], np.float32)\n",
        "                temp = img[top:top+img_size, left:left+img_size, :]\n",
        "                piece[:temp.shape[0], :temp.shape[1], :] = temp\n",
        "                crop.append(piece)\n",
        "                position.append([top, left])\n",
        "                batch_count += 1\n",
        "                if batch_count == batch_size:\n",
        "                    crop = np.array(crop)\n",
        "                    pred = model(crop)*255\n",
        "                    crop = []\n",
        "                    batch_count = 0\n",
        "                    for num, (t, l) in enumerate(position):\n",
        "                        piece = pred[num]\n",
        "                        h, w, c = result_img[t:t+img_size, l:l+img_size, :].shape\n",
        "                        result_img[t:t+img_size, l:l+img_size, :] += piece[:h, :w]\n",
        "                        voting_mask[t:t+img_size, l:l+img_size, :] += 1\n",
        "                    position = []\n",
        "        \n",
        "        result_img = result_img/voting_mask\n",
        "        result_img = result_img.astype(np.uint8)\n",
        "        results.append(result_img)\n",
        "        \n",
        "    return results"
      ],
      "metadata": {
        "id": "72keDOCynf8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evi_t7JLp6iS"
      },
      "source": [
        "import math\n",
        "def rmse_score(true, pred):\n",
        "    score = math.sqrt(np.mean((true-pred)**2))\n",
        "    return score\n",
        "\n",
        "def psnr_score(true, pred, pixel_max):\n",
        "    score = 20*np.log10(pixel_max/rmse_score(true, pred))\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4OGfiPvp6iS"
      },
      "source": [
        "img_size =256\n",
        "test_result = predict(train_input_files[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "IeblFdYvp6iT"
      },
      "source": [
        "for i, (input_path, label_path) in enumerate(zip(train_input_files[:10], train_label_files[:10])):\n",
        "    input_img = cv2.imread(input_path)\n",
        "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    targ_img = cv2.imread(label_path)\n",
        "    targ_img = cv2.cvtColor(targ_img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    pred_img = result[i]\n",
        "    pred_img=np.transpose(pred_img,(1,2,0))\n",
        "    \n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(input_img)\n",
        "    plt.title('input_img', fontsize=10)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(pred_img)\n",
        "    plt.title('output_img', fontsize=10)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(targ_img)\n",
        "    plt.title('target_img', fontsize=10)\n",
        "    plt.show()\n",
        "    print('input PSNR :', psnr_score(input_img.astype(float), targ_img.astype(float), 255))\n",
        "    print('output PSNR :', psnr_score(pred_img[i].astype(float), targ_img.astype(float), 255), '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSIqwL9Hp6iU"
      },
      "source": [
        "import zipfile\n",
        "def make_submission(result):\n",
        "    os.makedirs('submission', exist_ok=True)\n",
        "    os.chdir(\"./submission/\")\n",
        "    sub_imgs = []\n",
        "    for i, img in enumerate(result):\n",
        "        path = f'test_{20000+i}.png'\n",
        "        cv2.imwrite(path, img)\n",
        "        sub_imgs.append(path)\n",
        "    submission = zipfile.ZipFile(\"submission.zip\", 'w')\n",
        "    for path in sub_imgs:\n",
        "        submission.write(path)\n",
        "    submission.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzKIrRTT4lyP"
      },
      "source": [
        "make_submission(test_result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}